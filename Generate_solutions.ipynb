{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Importing of relevant functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.relpath('code' ))\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import copy\n",
    "import scipy.optimize as opt\n",
    "import matplotlib.pyplot as plt\n",
    "from Method_functions import *\n",
    "from Field_functions import *\n",
    "import pickle \n",
    "from pathlib import Path \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variation of parameters for the paper\n",
    "Here are the variables that are changed for the paper figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vary parameters here for creating the data for the different figures**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################################\n",
    "#########################################################################################################\n",
    "\n",
    "step_size = 0.1  # best to choose h=[0.01,0.02,0.04,0.08,0.1,0.2, 0.4, 0.8]  as for these are divisors of 28 and thus all numerical methods have the same end time\n",
    "\n",
    "alpha_value,beta_value,gamma_value=1,1,1\n",
    "# alpha_value,beta_value,gamma_value=1,0,0\n",
    "# alpha_value,beta_value,gamma_value=0.5,0.5,0.5\n",
    "\n",
    "\n",
    "# start guess that is close to the optimal control and thus allows for convergence to proper solution of root finding method\n",
    "# for large step-sizes, like 0.8 and first-order schemes it might be better to use e.g. 0.4, 0.2 as the initial guesses, as the default one is for a method that has converged to the real solution\n",
    "save_data_file = 'code/start_guess_traj.pkl'\n",
    "\n",
    "\n",
    "# set to False if one is interested in also getting the optimal solution of the control dependent case, for fig. 1 relevant\n",
    "skip_control_dependent_solution_search = False\n",
    "# set to False if one is interested to also generate the solution via the direct method, for fig 2 relevant\n",
    "skip_direct_minimization  = True\n",
    "\n",
    "#########################################################################################################\n",
    "#########################################################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Give the parameters needed for the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########\n",
    "# Dict that contains all parameters\n",
    "###########\n",
    "\n",
    "parameters = dict({ \"M\" : 10., \n",
    "                   \"t_0\" : 0, \"t_N\" : 3, \n",
    "                   \"q_0\" : np.array([[4.],[0]]), \"q_T\" : np.array([[-5.],[0]]), \n",
    "                   \"dim_u\" : 1,\n",
    "                   \"h\":step_size,\n",
    "                   \"N\": 0,\"alpha\":alpha_value, \n",
    "                   \"beta\":beta_value,\"gamma\":gamma_value,\n",
    "                   \"grav\" : 1, #grav=gravitational constant\n",
    "                   \"q_T_weight\": 1, \"dq_T_weight\": 1,\n",
    "                   \"times\":np.array([0]),\n",
    "                   \"d\" :1 #number rotations around\n",
    "                   }) \n",
    "\n",
    "parameters[\"dim_q\"] = len(parameters['q_0'])\n",
    "# parameters[\"t_N\"] = 1.5*end_Time_calc(parameters[\"d\"],parameters[\"M\"],parameters[\"grav\"],np.sqrt(parameters[\"q_0\"].flatten()@parameters[\"q_0\"].flatten()), np.sqrt(parameters[\"q_T\"].flatten()@parameters[\"q_T\"].flatten()))\n",
    "parameters[\"t_N\"] = 28  #Choose rounded time here, which is approximately the time value as calculated by the function in the paper. However this rounding enables one to discretize such that the total time is always fix, for the h-choices\n",
    "parameters[\"dq_T\"] = np.array([[0],[dphi_from_radius(abs(parameters[\"q_T\"][0,0]),parameters[\"grav\"],parameters[\"M\"])]])\n",
    "parameters[\"dq_T\"] = np.array([[0],[-abs(parameters[\"q_T\"][0][0])*parameters[\"dq_T\"][1][0]]])\n",
    "parameters[\"dq_0\"] = np.array([[0],[dphi_from_radius(parameters[\"q_0\"][0,0],parameters[\"grav\"],parameters[\"M\"])]])\n",
    "parameters[\"dq_0\"] = np.array([[0],[parameters[\"q_0\"][0][0]*parameters[\"dq_0\"][1][0]]])\n",
    "rescale_stepsize_parameters(parameters,parameters[\"h\"]) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 - Generate good starting values for efficient convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create start-guess for simulation\n",
    "\n",
    "\n",
    "with open(save_data_file, 'rb') as files:\n",
    "    initial_guess_data = pickle.load(files)\n",
    "\n",
    "q_d_start_guess = np.array(initial_guess_data['q_d'])\n",
    "lam_d_start_guess =np.array(initial_guess_data['lam_d'])\n",
    "u_d_start_guess = initial_guess_data['U_d']\n",
    "\n",
    "cs_q =  scipy.interpolate.CubicSpline(np.linspace(0,parameters[\"t_N\"],len(q_d_start_guess)), q_d_start_guess.reshape([len(q_d_start_guess),2]))\n",
    "cs_lam = scipy.interpolate.CubicSpline(np.linspace(0,parameters[\"t_N\"],len(lam_d_start_guess)), lam_d_start_guess.reshape([len(lam_d_start_guess),2]))  \n",
    "cs_u= scipy.interpolate.CubicSpline(np.linspace(0,parameters[\"t_N\"],len(u_d_start_guess)),u_d_start_guess)\n",
    "\n",
    "U_d_1_use = cs_u(np.array(parameters[\"times\"]) + parameters[\"beta\"]*parameters[\"h\"]).reshape(len(parameters[\"times\"]),1,1)\n",
    "U_d_2_use = cs_u(np.array(parameters[\"times\"]) + (1-parameters[\"beta\"])*parameters[\"h\"]).reshape(len(parameters[\"times\"]),1,1)\n",
    "\n",
    "q_d_use = cs_q(parameters[\"times\"]).reshape(len(parameters[\"times\"]),2,1)\n",
    "lambda_d_use = cs_lam(parameters[\"times\"]).reshape(len(parameters[\"times\"]),2,1)\n",
    "mu_use = initial_guess_data['mu']\n",
    "nu_use = initial_guess_data['nu']\n",
    "\n",
    " \n",
    " #can plot here the trajectories to see what they look like\n",
    "# plot_curve(q_d_use,\"example_trajectory\",parameters);\n",
    "# plt.show()\n",
    "# plt.plot(np.array(parameters[\"times\"]) + parameters[\"beta\"]*parameters[\"h\"], U_d_1_use.flatten())\n",
    "# plt.plot(np.array(parameters[\"times\"]) + (1-parameters[\"beta\"])*parameters[\"h\"], U_d_2_use.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4.1 - Create solution for the u-independent Lagrangian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no-u dependent case\n",
    "\n",
    "stacked_startvals = stack_variables_two_Us(q_d_use,lambda_d_use,mu_use,nu_use,U_d_1_use,U_d_2_use,False)\n",
    "optimality_conditions = optimality_conditions_generator(vector_field_eval,covector_field_eval,parameters)\n",
    "optifunc = lambda X: np.concatenate(optimality_conditions.create_all_optimality_conditions_no_u(*unstack_variables_two_Us(X,parameters[\"dim_q\"],parameters[\"dim_u\"],parameters[\"N\"],False)[:-2],U_d_1_use,U_d_2_use))\n",
    "\n",
    "solution_no_u = opt.root(fun=optifunc,x0=stacked_startvals,method='lm')\n",
    "#Alternative root finding method, sometimes faster, but typically not as accurate:\n",
    "# solution_no_u = opt.root(fun=optifunc,x0=stacked_startvals,method='hybr')\n",
    "\n",
    "#print solution message\n",
    "solution_no_u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4.2 - Create solution for the u-dependent Lagrangian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically will be slower than the independent case by virtue of having more variables (the explicit treatment of the controls)\n",
    "\n",
    "Can be skipped if not considered, e.g. for the generation of fig. 3\n",
    "\n",
    "Will be skipped via setting the flag 'skip_control_dependent_solution_search' to True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the simulation with the startvalues from the control independent case, as they should lead to the same solutions\n",
    "# that typically guarantees fast convergence\n",
    "\n",
    "if not skip_control_dependent_solution_search:\n",
    "    q_d_use,lambda_d_use,mu_use,nu_use  = unstack_variables_two_Us(solution_no_u.x,parameters[\"dim_q\"],parameters[\"dim_u\"],parameters[\"N\"],False)[:-2]\n",
    "    U_d_1_use = np.array([get_u_from_lambda(x,y,parameters) for (x,y) in zip(lambda_d_use,q_d_use)])\n",
    "    U_d_2_use = np.array([get_u_from_lambda(x,y,parameters) for (x,y) in zip(lambda_d_use,q_d_use)])\n",
    "\n",
    "    stacked_startvals = stack_variables_two_Us(q_d_use,lambda_d_use,mu_use,nu_use,U_d_1_use,U_d_2_use)\n",
    "\n",
    "    dim_q = len(q_d_use[0])\n",
    "    dim_u = len(U_d_1_use[0])\n",
    "\n",
    "    optimality_conditions = optimality_conditions_generator(vector_field_u_eval,covector_field_u_eval,parameters)\n",
    "    optifunc = lambda X: np.concatenate(optimality_conditions.create_all_optimality_conditions(*unstack_variables_two_Us(X,dim_q,dim_u,parameters[\"N\"])))\n",
    "\n",
    "    solution_u = opt.root(fun=optifunc,x0=stacked_startvals,method='lm')\n",
    "    solution_u\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it can make sense to run the root finder again, due to U_d_1, U_d_2 being sometimes the same variables, resulting in a highly deficit jacobian \n",
    "e.g. for alpha=beta=gamma = 1. \n",
    "\n",
    "This makes the convergence to the solution sometimes unstable. Redoing the root finding with the prior solution helps there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quick check that can be done to see whether the root finder was able to properly find a solution. If no solution is found, then typically the conserved quantity is not conserved\n",
    "# q_d_sol_test, lam_d_sol_test, mu_test,nu_test,u_d_1_test = unstack_variables(solution_no_u.x,dim_q,dim_u, parameters[\"N\"],False) \n",
    "# from Analysis_helper_functions import calculate_conserved_quantity_evolution\n",
    "# conserved_I_evo = calculate_conserved_quantity_evolution(q_d_sol_test,lam_d_sol_test,u_d_1_test,u_d_1_test,vector_field_eval,covector_field_eval,parameters)\n",
    "\n",
    "# plt.plot(conserved_I_evo,'--*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5 - Save solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not solution_no_u.success:\n",
    "        print('did not find a solution in control dependent case, not storing the result')\n",
    "else:\n",
    "    storage_dict = dict()\n",
    "    storage_dict[\"q_d\"],storage_dict[\"lam_d\"],storage_dict[\"mu\"],storage_dict[\"nu\"],storage_dict[\"U_d\"]  = unstack_variables(solution_no_u.x,parameters[\"dim_q\"],parameters[\"dim_u\"],parameters[\"N\"],False)\n",
    "    storage_dict[\"U_d\"]  = [get_u_from_lambda(x,y,parameters) for (x,y) in zip(storage_dict[\"lam_d\"],storage_dict[\"q_d\"])]\n",
    "    storage_dict[\"parameters\"] = parameters\n",
    "    storage_dict[\"solution_info\"] = solution_no_u\n",
    "    dirpath = \"data/no_u_dep_data_\"+\"a=\" + str(parameters[\"alpha\"]) + \"b=\" + str(parameters[\"beta\"]) +\"g=\" + str(parameters[\"gamma\"])\n",
    "    Path(dirpath).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    no_u_dep_file_name = dirpath+\"/no_u_dep_data_\" +\"a=\" + str(parameters[\"alpha\"]) + \"b=\" + str(parameters[\"beta\"]) +\"g=\" + str(parameters[\"gamma\"])  +\"h=\" + str(parameters[\"h\"]) + \".pkl\"\n",
    "    with open(no_u_dep_file_name, 'wb') as ffile:\n",
    "        pickle.dump(storage_dict, ffile)\n",
    "        ffile.close()\n",
    "    \n",
    "if not skip_control_dependent_solution_search:\n",
    "    if not solution_u.success:\n",
    "        print('did not find a solution in control dependent case, not storing the result')\n",
    "    else:\n",
    "        storage_dict = dict()\n",
    "        storage_dict[\"q_d\"],storage_dict[\"lam_d\"],storage_dict[\"mu\"],storage_dict[\"nu\"],storage_dict[\"U_d_1\"], storage_dict[\"U_d_2\"]  = unstack_variables_two_Us(solution_u.x,parameters[\"dim_q\"],parameters[\"dim_u\"],parameters[\"N\"])\n",
    "        storage_dict[\"parameters\"] = parameters\n",
    "        storage_dict[\"solution_info\"] = solution_u\n",
    "\n",
    "        dirpath = \"data/new_u_dep_data_\"+\"a=\" + str(parameters[\"alpha\"]) + \"b=\" + str(parameters[\"beta\"]) +\"g=\" + str(parameters[\"gamma\"])\n",
    "        Path(dirpath).mkdir(parents=True, exist_ok=True)\n",
    "        u_dep_file_name = dirpath+\"/new_u_dep_data_\" +\"a=\" + str(parameters[\"alpha\"]) + \"b=\" + str(parameters[\"beta\"]) +\"g=\" + str(parameters[\"gamma\"])   +\"h=\" + str(parameters[\"h\"]) + \".pkl\"\n",
    "        with open(u_dep_file_name, 'wb') as ffile:\n",
    "            pickle.dump(storage_dict, ffile)\n",
    "            ffile.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard direct approach comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard approach calc\n",
    "if not skip_direct_minimization:\n",
    "    optimality_conditions = optimality_conditions_generator(vector_field_u_eval,covector_field_u_eval,parameters)\n",
    "    q_d_use1, lam_d_use1, mu_use1, nu_use1,_,_ = unstack_variables_two_Us(solution_no_u.x,dim_q,dim_u,parameters[\"N\"],False)\n",
    "    # q_d_use1, lam_d_use1, mu_use1, nu_use1,U_d_use,_ = unstack_variables_two_Us(solution_u.x,dim_q,dim_u,parameters[\"N\"])\n",
    "\n",
    "    controls_nodes = np.array([get_u_from_lambda(x,y,parameters) for (x,y) in zip(lam_d_use1,q_d_use1)]).flatten()\n",
    "    midpoint_controls_startguess = np.array([(controls_nodes[i]+controls_nodes[i+1])/2.0 for i in range(len(controls_nodes)-1) ])\n",
    "    # solution_traj = optimality_conditions.standard_create_running_termina_cost(midpoint_controls)\n",
    "    cost_function=lambda X : sum(optimality_conditions.standard_create_running_termina_cost(np.reshape(X,[len(X),1,1]))[0])\n",
    "\n",
    "    minimized_sol = opt.minimize(cost_function,np.array(midpoint_controls_startguess).flatten(),method='SLSQP')\n",
    "    u_vals_standard = np.reshape(minimized_sol.x,[parameters[\"N\"]+1,1,1])\n",
    "    solvals,q_vals_standard,v_vals_standard = optimality_conditions.standard_create_running_termina_cost(u_vals_standard)\n",
    "    if not minimized_sol.success:\n",
    "        print('did not find a solution in control dependent case, not storing the result')\n",
    "    else:\n",
    "        storage_dict = dict()\n",
    "        storage_dict[\"q_d\"],storage_dict[\"v_d\"],storage_dict[\"U_d\"]  = q_vals_standard,v_vals_standard,u_vals_standard\n",
    "        storage_dict[\"parameters\"] = parameters\n",
    "        storage_dict[\"minimizer_info\"] = minimized_sol\n",
    "        dirpath = \"data/standard_comparison_midpoint\"\n",
    "        Path(dirpath).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        standard_file_name = dirpath+\"/standard_comparison_midpoint_\"   +\"h=\" + str(parameters[\"h\"]) + \".pkl\"\n",
    "\n",
    "        with open(standard_file_name, 'wb') as ffile:\n",
    "            pickle.dump(storage_dict, ffile)\n",
    "            ffile.close()\n",
    "\n",
    "#can also plot here the curve if interested\n",
    "\n",
    "# plot_curve(q_vals_standard,'test_minimizer',parameters)\n",
    "# plt.show()\n",
    "# plt.plot(parameters[\"times\"][:-1],(u_vals_standard.flatten()[:-1]+u_vals_standard.flatten()[1:])/2,label='standard')\n",
    "# plt.plot(initial_guess_data_midpoint['parameters']['times'][:-1],(np.array(initial_guess_data_midpoint['U_d']).flatten()[1:]+np.array(initial_guess_data_midpoint['U_d']).flatten()[:-1])/2 ,label='midpoint_new_sol')\n",
    "# plt.legend()\n",
    "# plt.plot((u_vals_standard.flatten()))\n",
    "# plt.ylim([-0.001,0.005])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
